{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digital Marketing MSB 109 \n",
    "\n",
    "## A Brief Introduction on Text Analysis And Scraping (II)\n",
    "\n",
    "### Nur Yaldiz \n",
    "    Graduating Phd Candidate\n",
    "    UiS Business School, Department of Economics and Finance, Behavioral Economics \n",
    "                                                                            November 1, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[What is a working directory?](https://www.geeksforgeeks.org/os-module-python-examples/)\n",
    "\n",
    "   import os module\n",
    "   \n",
    "   use os.getcwd() to get your current working directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\2918261\\\\Dropbox\\\\Marketing\\\\Meeting_May_11_2021\\\\Codes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the new working directory \n",
    "   \n",
    "   Create an empty folder on your desktop.\n",
    "   \n",
    "   Name this folder: Second_Module\n",
    "   \n",
    "   Save the data set (add the name of the json file here) in this folder\n",
    "   \n",
    "   Click right on the folder and go to the final line (egenskaper in Norwegian change this to English)\n",
    "   \n",
    "   Get the path from “generelt.” The line after “plassering” gives the path.\n",
    "   \n",
    "   Copy this path within the quotes of os.chdir (“…”)\n",
    "   \n",
    "   Change \\ to /\n",
    "   \n",
    "   At the end of the path, add your file name: “/Second_Module”\n",
    "\n",
    "To change a working directory:\n",
    "    \n",
    "  [import os](https://www.geeksforgeeks.org/change-current-working-directory-with-python/)\n",
    "  \n",
    "  os.chdir('path') change the current working directory to a scpecified path\n",
    "  \n",
    "  os.getcwd verifies that the change is successful.  \n",
    "  (You can also use os.getcwd() to find your current working directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C://Users//2918261//Dropbox//Marketing//Meeting_May_11_2021//Codes')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we obtain the data? \n",
    "\n",
    "### Run the codes and explore in your own time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TWINT](https://github.com/twintproject/twint) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start scraping we need to import twint and nest_asyncio. nest_asyncio helps us to run concurrent event loops apply() is used to pass a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint \n",
    "import nest_asyncio \n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweets about Elon Musk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we scrape tweets with no specific limits. \n",
    "\n",
    "We can store it in JSON format by setting c.Store_json to True \n",
    "\n",
    "Also, we can hide the output on out screen since a display of massive data may be problematic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = twint.Config()\n",
    "\n",
    "c.Search = \"#elonmusk\"\n",
    "\n",
    "c.Hide_output = True\n",
    "\n",
    "c.Store_json = True\n",
    "\n",
    "c.Output = 'ElonMusk.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save it as a json file and explore this dataset.\n",
    "\n",
    "We need to set the lines parameters to True, since tweets are seperated in lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('ElonMusk.json' , lines = True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Goal for today \n",
    "### Run simple analysis on the #elonmusk dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing the dataset by using pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is saved line by line, when importing it we use the same parameter: lines = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Musk = pd.read_json('C:/Users/2918261/Dropbox/Marketing/Meeting_May_11_2021/Codes/ElonMusk.json', lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List function give us the column names of a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(Musk.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the subset of the data with double square brackets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Musk[['tweet', 'language', 'date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Only select tweets in English "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will follow a simple approach by selecting rows that have 'en' on the language column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Musk = Musk[Musk['language'] == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating tweets in other languages reduces the sample size from 23,172 to 16,101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Musk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Reset index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are only working with one dataframe but when you are working with multiple dataframes reindexing can be crucial after eliminating some rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Musk = Musk.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop = True avoids double indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Musk.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Musk.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Explore usernames "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this dataframe has 236 tweets from Elon Musk himself.\n",
    "\n",
    "We can slice the data as Musk and non-Musk. \n",
    "\n",
    "Tweets from Musk definitely makes a smaller dataset, but we can gain some insights on Musk's tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Musk[Musk['name'] == 'Elon Musk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Extract Musk tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElonM = Musk[Musk['name'] == 'Elon Musk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len (ElonM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to reset index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElonM = ElonM.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElonM.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElonM.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Word Count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our word count function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_word_count(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElonM['tweet'].apply(simple_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElonM['tweet_word_count'] = ElonM['tweet'].apply(simple_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElonM['tweet_word_count'].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need [matplotlib.pyplot]('https://matplotlib.org/stable/tutorials/introductory/pyplot.html') to produce graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElonM.plot.scatter(y = 'tweet_word_count', x = 'date')\n",
    "'''the next command avoids the dates from overlapping'''\n",
    "plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the media outlets to understand what was causing high tweet traffic on specific dates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can plot tweets based on dates with value_counts()\n",
    "\n",
    "[%matplotlib inline](https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline) is a magic command that you may need to instert while plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ElonM['date'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat these excercises on Non-Musk tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words and CountVectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we have focused on the numbers. However, we may need to know which words are the most frequent.\n",
    "\n",
    "A simple approach is to employ [Bag of Words model](https://en.wikipedia.org/wiki/Bag-of-words_model). \n",
    "\n",
    "Although easy to apply, BoW does not consider the order of words. Put differently, you may not know whether a word is a noun or a verb. \n",
    "\n",
    "In any case, BoW gives us a necessary understanding of textual data. \n",
    "\n",
    "[Scikit library](https://scikit-learn.org/stable/index.html) of Python provides us the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), so we have readily available algorithm.\n",
    "\n",
    "It is common to refer to words as features in [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing) (text data analysis). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set the parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example we rely on the default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit() produces the vocabulary that we will count in the subsequent steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(ElonM['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, vectorizer returns a set of parameters that are used to build vocabulary.  \n",
    "\n",
    "Explore what each parameter does after this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the vocabulary list with get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: transform() the text into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_array = vectorizer.transform(ElonM['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform returns a sparse matrix. \n",
    "\n",
    "This means that transform only retuns the local of cells with nonzero values. \n",
    "\n",
    "For example, (0, 0) refers to row and column with zero index, which is followed by 1, refers to the value of that cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_frequency_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: convert sparse arrays to a matrix with todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a matrix so that pandas can read the matrix (dense) version of the data to build a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_array.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer matrix to a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word_frequency_array.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Add the column names with vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe above has numbers instead of column names, \n",
    "we will transfer the corresponding vocabulary by applying get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_example = pd.DataFrame(word_frequency_array.todense(),\n",
    "                              columns = vectorizer.get_feature_names())\n",
    "\n",
    "simple_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_example.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: get the most common words with sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will simply calculate the frequency of each word by taking the sum of their occurance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_example.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort the values from largest to smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_example.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_example.sum().sort_values(ascending = False)[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Merge the ElonM dataframe with WordFrequency dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both dataframe follow the same order we can combine them horizontally by setting [axis = 1]('https://pandas.pydata.org/docs/reference/api/pandas.concat.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final = pd.concat([ElonM, simple_example], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
